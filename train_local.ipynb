{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413d2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import os\n",
    "from transformer_flow import Model\n",
    "import utils\n",
    "import pathlib\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\" # set GPU\n",
    "\n",
    "utils.set_random_seed(100)\n",
    "notebook_output_path = pathlib.Path('runs/notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "Unitary logdet: 0.00\n",
      "Unitary logdet: -0.00\n",
      "Unitary logdet: -0.00\n",
      "Unitary logdet: 0.00\n",
      "Number of parameters: 3.24M\n",
      "epoch 0 lr 0.000500 loss -0.8450\n",
      "layer norms 1.2346 1.2148 0.9755 0.9531\n",
      "logdet: 1.7785, prior p: 0.4766\n",
      "epoch 1 lr 0.000500 loss -1.3738\n",
      "layer norms 1.2000 0.8658 0.6879 0.9517\n",
      "logdet: 1.8950, prior p: 0.4759\n",
      "epoch 2 lr 0.000499 loss -1.4457\n",
      "layer norms 0.9725 0.8269 0.6558 0.9906\n",
      "logdet: 1.9576, prior p: 0.4953\n",
      "epoch 3 lr 0.000499 loss -1.4771\n",
      "layer norms 0.9077 0.7974 0.6192 1.0341\n",
      "logdet: 2.0135, prior p: 0.5171\n",
      "epoch 4 lr 0.000498 loss -1.4974\n",
      "layer norms 0.8630 0.7712 0.5666 1.0048\n",
      "logdet: 2.0075, prior p: 0.5024\n",
      "sampling complete\n",
      "epoch 5 lr 0.000497 loss -1.5136\n",
      "layer norms 0.8490 0.7687 0.5534 1.0387\n",
      "logdet: 2.0406, prior p: 0.5194\n",
      "epoch 6 lr 0.000495 loss -1.5280\n",
      "layer norms 0.8320 0.7304 0.4761 0.9781\n",
      "logdet: 2.0216, prior p: 0.4890\n",
      "epoch 7 lr 0.000494 loss -1.5400\n",
      "layer norms 0.8306 0.7381 0.4755 0.9805\n",
      "logdet: 2.0233, prior p: 0.4902\n",
      "epoch 8 lr 0.000492 loss -1.5491\n",
      "layer norms 0.8218 0.7432 0.4744 0.9854\n",
      "logdet: 2.0412, prior p: 0.4927\n",
      "epoch 9 lr 0.000490 loss -1.5561\n",
      "layer norms 0.8291 0.7466 0.4764 0.9570\n",
      "logdet: 2.0326, prior p: 0.4785\n",
      "sampling complete\n",
      "epoch 10 lr 0.000488 loss -1.5615\n",
      "layer norms 0.8288 0.7481 0.4692 0.9856\n",
      "logdet: 2.0658, prior p: 0.4928\n",
      "epoch 11 lr 0.000485 loss -1.5657\n",
      "layer norms 0.8309 0.7510 0.4666 0.9977\n",
      "logdet: 2.0658, prior p: 0.4988\n",
      "epoch 12 lr 0.000482 loss -1.5698\n",
      "layer norms 0.8242 0.7350 0.4412 1.0154\n",
      "logdet: 2.0682, prior p: 0.5077\n",
      "epoch 13 lr 0.000479 loss -1.5727\n",
      "layer norms 0.8394 0.7634 0.4681 0.9992\n",
      "logdet: 2.0770, prior p: 0.4996\n",
      "epoch 14 lr 0.000476 loss -1.5751\n",
      "layer norms 0.8460 0.7631 0.4623 0.9923\n",
      "logdet: 2.0778, prior p: 0.4961\n",
      "sampling complete\n",
      "epoch 15 lr 0.000472 loss -1.5777\n",
      "layer norms 0.8433 0.7703 0.4665 1.0083\n",
      "logdet: 2.0855, prior p: 0.5041\n",
      "epoch 16 lr 0.000469 loss -1.5798\n",
      "layer norms 0.8499 0.7812 0.4758 1.0179\n",
      "logdet: 2.1006, prior p: 0.5089\n",
      "epoch 17 lr 0.000465 loss -1.5819\n",
      "layer norms 0.8566 0.7922 0.4846 0.9713\n",
      "logdet: 2.0713, prior p: 0.4856\n",
      "epoch 18 lr 0.000460 loss -1.5836\n",
      "layer norms 0.8659 0.8022 0.4933 0.9713\n",
      "logdet: 2.0753, prior p: 0.4856\n",
      "epoch 19 lr 0.000456 loss -1.5851\n",
      "layer norms 0.8690 0.8107 0.4969 0.9926\n",
      "logdet: 2.0841, prior p: 0.4963\n",
      "sampling complete\n",
      "epoch 20 lr 0.000451 loss -1.5862\n",
      "layer norms 0.8780 0.8168 0.5024 0.9971\n",
      "logdet: 2.0890, prior p: 0.4985\n",
      "epoch 21 lr 0.000447 loss -1.5879\n",
      "layer norms 0.8748 0.8194 0.5059 1.0034\n",
      "logdet: 2.0914, prior p: 0.5017\n",
      "epoch 22 lr 0.000442 loss -1.5892\n",
      "layer norms 0.8907 0.8359 0.5167 0.9852\n",
      "logdet: 2.0831, prior p: 0.4926\n",
      "epoch 23 lr 0.000436 loss -1.5904\n",
      "layer norms 0.8878 0.8291 0.5064 0.9919\n",
      "logdet: 2.0863, prior p: 0.4959\n",
      "epoch 24 lr 0.000431 loss -1.5913\n",
      "layer norms 0.8926 0.8377 0.5156 0.9895\n",
      "logdet: 2.0858, prior p: 0.4948\n",
      "sampling complete\n",
      "epoch 25 lr 0.000426 loss -1.5925\n",
      "layer norms 0.8936 0.8467 0.5315 0.9853\n",
      "logdet: 2.0921, prior p: 0.4927\n",
      "epoch 26 lr 0.000420 loss -1.5936\n",
      "layer norms 0.9114 0.8598 0.5351 1.0039\n",
      "logdet: 2.0884, prior p: 0.5019\n",
      "epoch 27 lr 0.000414 loss -1.5943\n",
      "layer norms 0.9067 0.8584 0.5317 1.0037\n",
      "logdet: 2.0963, prior p: 0.5019\n",
      "epoch 28 lr 0.000408 loss -1.5951\n",
      "layer norms 0.9116 0.8660 0.5369 1.0242\n",
      "logdet: 2.1059, prior p: 0.5121\n",
      "epoch 29 lr 0.000402 loss -1.5958\n",
      "layer norms 0.9111 0.8663 0.5343 1.0048\n",
      "logdet: 2.0984, prior p: 0.5024\n",
      "sampling complete\n",
      "epoch 30 lr 0.000395 loss -1.5964\n",
      "layer norms 0.9258 0.8849 0.5581 1.0174\n",
      "logdet: 2.1022, prior p: 0.5087\n",
      "epoch 31 lr 0.000389 loss -1.5973\n",
      "layer norms 0.9222 0.8835 0.5573 0.9966\n",
      "logdet: 2.0954, prior p: 0.4983\n",
      "epoch 32 lr 0.000382 loss -1.5982\n",
      "layer norms 0.9291 0.8983 0.5693 1.0086\n",
      "logdet: 2.1042, prior p: 0.5043\n",
      "epoch 33 lr 0.000375 loss -1.5988\n",
      "layer norms 0.9280 0.8955 0.5711 0.9861\n",
      "logdet: 2.0958, prior p: 0.4930\n",
      "epoch 34 lr 0.000368 loss -1.5997\n",
      "layer norms 0.9360 0.9077 0.5762 0.9951\n",
      "logdet: 2.0986, prior p: 0.4976\n",
      "sampling complete\n",
      "epoch 35 lr 0.000361 loss -1.6001\n",
      "layer norms 0.9331 0.9031 0.5730 1.0056\n",
      "logdet: 2.1023, prior p: 0.5028\n",
      "epoch 36 lr 0.000354 loss -1.6005\n",
      "layer norms 0.9330 0.9052 0.5772 0.9809\n",
      "logdet: 2.0940, prior p: 0.4904\n",
      "epoch 37 lr 0.000347 loss -1.6013\n",
      "layer norms 0.9361 0.9132 0.5835 0.9941\n",
      "logdet: 2.0996, prior p: 0.4971\n",
      "epoch 38 lr 0.000340 loss -1.6019\n",
      "layer norms 0.9483 0.9263 0.5929 1.0110\n",
      "logdet: 2.1121, prior p: 0.5055\n",
      "epoch 39 lr 0.000332 loss -1.6024\n",
      "layer norms 0.9473 0.9251 0.5946 0.9930\n",
      "logdet: 2.0951, prior p: 0.4965\n",
      "sampling complete\n",
      "epoch 40 lr 0.000325 loss -1.6030\n",
      "layer norms 0.9585 0.9382 0.6023 0.9940\n",
      "logdet: 2.0973, prior p: 0.4970\n",
      "epoch 41 lr 0.000317 loss -1.6035\n",
      "layer norms 0.9537 0.9375 0.6027 0.9837\n",
      "logdet: 2.0965, prior p: 0.4919\n",
      "epoch 42 lr 0.000309 loss -1.6037\n",
      "layer norms 0.9456 0.9299 0.6013 0.9987\n",
      "logdet: 2.1006, prior p: 0.4994\n",
      "epoch 43 lr 0.000302 loss -1.6045\n",
      "layer norms 0.9493 0.9373 0.6065 0.9949\n",
      "logdet: 2.1052, prior p: 0.4974\n",
      "epoch 44 lr 0.000294 loss -1.6052\n",
      "layer norms 0.9485 0.9339 0.6012 1.0055\n",
      "logdet: 2.1075, prior p: 0.5027\n",
      "sampling complete\n",
      "epoch 45 lr 0.000286 loss -1.6054\n",
      "layer norms 0.9596 0.9482 0.6133 1.0134\n",
      "logdet: 2.1126, prior p: 0.5067\n",
      "epoch 46 lr 0.000278 loss -1.6058\n",
      "layer norms 0.9607 0.9485 0.6150 1.0005\n",
      "logdet: 2.1078, prior p: 0.5002\n",
      "epoch 47 lr 0.000270 loss -1.6062\n",
      "layer norms 0.9513 0.9428 0.6087 1.0012\n",
      "logdet: 2.1077, prior p: 0.5006\n",
      "epoch 48 lr 0.000262 loss -1.6066\n",
      "layer norms 0.9575 0.9522 0.6208 1.0004\n",
      "logdet: 2.1019, prior p: 0.5002\n",
      "epoch 49 lr 0.000254 loss -1.6072\n",
      "layer norms 0.9643 0.9576 0.6244 0.9936\n",
      "logdet: 2.1078, prior p: 0.4968\n",
      "sampling complete\n",
      "epoch 50 lr 0.000247 loss -1.6076\n",
      "layer norms 0.9626 0.9576 0.6257 1.0143\n",
      "logdet: 2.1126, prior p: 0.5072\n",
      "epoch 51 lr 0.000239 loss -1.6079\n",
      "layer norms 0.9602 0.9546 0.6196 1.0036\n",
      "logdet: 2.1009, prior p: 0.5018\n",
      "epoch 52 lr 0.000231 loss -1.6085\n",
      "layer norms 0.9563 0.9565 0.6226 1.0176\n",
      "logdet: 2.1159, prior p: 0.5088\n",
      "epoch 53 lr 0.000223 loss -1.6089\n",
      "layer norms 0.9591 0.9639 0.6315 0.9977\n",
      "logdet: 2.1144, prior p: 0.4989\n",
      "epoch 54 lr 0.000215 loss -1.6092\n",
      "layer norms 0.9696 0.9741 0.6424 0.9983\n",
      "logdet: 2.1111, prior p: 0.4992\n",
      "sampling complete\n",
      "epoch 55 lr 0.000207 loss -1.6097\n",
      "layer norms 0.9573 0.9646 0.6347 1.0011\n",
      "logdet: 2.1092, prior p: 0.5006\n",
      "epoch 56 lr 0.000199 loss -1.6100\n",
      "layer norms 0.9726 0.9794 0.6477 1.0040\n",
      "logdet: 2.1156, prior p: 0.5020\n",
      "epoch 57 lr 0.000192 loss -1.6103\n",
      "layer norms 0.9611 0.9708 0.6385 0.9970\n",
      "logdet: 2.1090, prior p: 0.4985\n",
      "epoch 58 lr 0.000184 loss -1.6108\n",
      "layer norms 0.9614 0.9708 0.6365 0.9885\n",
      "logdet: 2.1033, prior p: 0.4943\n",
      "epoch 59 lr 0.000176 loss -1.6111\n",
      "layer norms 0.9616 0.9724 0.6411 0.9944\n",
      "logdet: 2.1122, prior p: 0.4972\n",
      "sampling complete\n",
      "epoch 60 lr 0.000169 loss -1.6113\n",
      "layer norms 0.9635 0.9738 0.6395 1.0052\n",
      "logdet: 2.1123, prior p: 0.5026\n",
      "epoch 61 lr 0.000161 loss -1.6117\n",
      "layer norms 0.9646 0.9798 0.6458 0.9963\n",
      "logdet: 2.1072, prior p: 0.4982\n",
      "epoch 62 lr 0.000154 loss -1.6121\n",
      "layer norms 0.9645 0.9769 0.6452 0.9912\n",
      "logdet: 2.1038, prior p: 0.4956\n",
      "epoch 63 lr 0.000147 loss -1.6124\n",
      "layer norms 0.9543 0.9707 0.6431 0.9979\n",
      "logdet: 2.1164, prior p: 0.4989\n",
      "epoch 64 lr 0.000140 loss -1.6124\n",
      "layer norms 0.9630 0.9787 0.6468 1.0108\n",
      "logdet: 2.1152, prior p: 0.5054\n",
      "sampling complete\n",
      "epoch 65 lr 0.000133 loss -1.6128\n",
      "layer norms 0.9543 0.9738 0.6453 1.0029\n",
      "logdet: 2.1159, prior p: 0.5014\n",
      "epoch 66 lr 0.000126 loss -1.6131\n",
      "layer norms 0.9637 0.9824 0.6520 0.9979\n",
      "logdet: 2.1165, prior p: 0.4990\n",
      "epoch 67 lr 0.000119 loss -1.6136\n",
      "layer norms 0.9565 0.9762 0.6446 1.0077\n",
      "logdet: 2.1169, prior p: 0.5039\n",
      "epoch 68 lr 0.000112 loss -1.6139\n",
      "layer norms 0.9590 0.9803 0.6464 0.9884\n",
      "logdet: 2.1084, prior p: 0.4942\n",
      "epoch 69 lr 0.000106 loss -1.6141\n",
      "layer norms 0.9540 0.9785 0.6454 0.9913\n",
      "logdet: 2.1155, prior p: 0.4956\n",
      "sampling complete\n",
      "epoch 70 lr 0.000099 loss -1.6144\n",
      "layer norms 0.9608 0.9825 0.6521 0.9984\n",
      "logdet: 2.1132, prior p: 0.4992\n",
      "epoch 71 lr 0.000093 loss -1.6145\n",
      "layer norms 0.9593 0.9844 0.6511 0.9982\n",
      "logdet: 2.1120, prior p: 0.4991\n",
      "epoch 72 lr 0.000087 loss -1.6150\n",
      "layer norms 0.9621 0.9892 0.6573 0.9982\n",
      "logdet: 2.1142, prior p: 0.4991\n",
      "epoch 73 lr 0.000081 loss -1.6152\n",
      "layer norms 0.9545 0.9787 0.6468 0.9993\n",
      "logdet: 2.1136, prior p: 0.4997\n",
      "epoch 74 lr 0.000075 loss -1.6154\n",
      "layer norms 0.9589 0.9849 0.6507 1.0063\n",
      "logdet: 2.1156, prior p: 0.5031\n",
      "sampling complete\n",
      "epoch 75 lr 0.000070 loss -1.6156\n",
      "layer norms 0.9552 0.9851 0.6519 0.9984\n",
      "logdet: 2.1146, prior p: 0.4992\n",
      "epoch 76 lr 0.000065 loss -1.6158\n",
      "layer norms 0.9476 0.9774 0.6483 1.0011\n",
      "logdet: 2.1175, prior p: 0.5005\n",
      "epoch 77 lr 0.000059 loss -1.6160\n",
      "layer norms 0.9534 0.9822 0.6496 1.0077\n",
      "logdet: 2.1120, prior p: 0.5039\n",
      "epoch 78 lr 0.000054 loss -1.6163\n",
      "layer norms 0.9466 0.9773 0.6481 0.9869\n",
      "logdet: 2.1174, prior p: 0.4934\n",
      "epoch 79 lr 0.000050 loss -1.6165\n",
      "layer norms 0.9497 0.9803 0.6480 1.0039\n",
      "logdet: 2.1155, prior p: 0.5020\n",
      "sampling complete\n",
      "epoch 80 lr 0.000045 loss -1.6166\n",
      "layer norms 0.9463 0.9756 0.6466 1.0024\n",
      "logdet: 2.1171, prior p: 0.5012\n",
      "epoch 81 lr 0.000041 loss -1.6170\n",
      "layer norms 0.9504 0.9816 0.6514 1.0001\n",
      "logdet: 2.1133, prior p: 0.5000\n",
      "epoch 82 lr 0.000036 loss -1.6170\n",
      "layer norms 0.9549 0.9852 0.6537 0.9970\n",
      "logdet: 2.1138, prior p: 0.4985\n",
      "epoch 83 lr 0.000032 loss -1.6173\n",
      "layer norms 0.9366 0.9718 0.6441 1.0053\n",
      "logdet: 2.1216, prior p: 0.5026\n",
      "epoch 84 lr 0.000029 loss -1.6174\n",
      "layer norms 0.9505 0.9806 0.6505 0.9989\n",
      "logdet: 2.1128, prior p: 0.4995\n",
      "sampling complete\n",
      "epoch 85 lr 0.000025 loss -1.6176\n",
      "layer norms 0.9492 0.9832 0.6529 0.9984\n",
      "logdet: 2.1204, prior p: 0.4992\n",
      "epoch 86 lr 0.000022 loss -1.6179\n",
      "layer norms 0.9541 0.9860 0.6523 0.9905\n",
      "logdet: 2.1097, prior p: 0.4952\n",
      "epoch 87 lr 0.000019 loss -1.6179\n",
      "layer norms 0.9409 0.9748 0.6437 1.0033\n",
      "logdet: 2.1159, prior p: 0.5016\n",
      "epoch 88 lr 0.000016 loss -1.6181\n",
      "layer norms 0.9429 0.9766 0.6500 0.9999\n",
      "logdet: 2.1168, prior p: 0.4999\n",
      "epoch 89 lr 0.000013 loss -1.6181\n",
      "layer norms 0.9471 0.9796 0.6520 0.9980\n",
      "logdet: 2.1178, prior p: 0.4990\n",
      "sampling complete\n",
      "epoch 90 lr 0.000011 loss -1.6181\n",
      "layer norms 0.9383 0.9750 0.6464 0.9972\n",
      "logdet: 2.1190, prior p: 0.4986\n",
      "epoch 91 lr 0.000009 loss -1.6184\n",
      "layer norms 0.9407 0.9770 0.6494 1.0007\n",
      "logdet: 2.1214, prior p: 0.5003\n",
      "epoch 92 lr 0.000007 loss -1.6184\n",
      "layer norms 0.9414 0.9772 0.6489 1.0070\n",
      "logdet: 2.1227, prior p: 0.5035\n",
      "epoch 93 lr 0.000006 loss -1.6185\n",
      "layer norms 0.9485 0.9842 0.6546 1.0011\n",
      "logdet: 2.1203, prior p: 0.5006\n",
      "epoch 94 lr 0.000004 loss -1.6185\n",
      "layer norms 0.9419 0.9768 0.6489 1.0009\n",
      "logdet: 2.1172, prior p: 0.5005\n",
      "sampling complete\n",
      "epoch 95 lr 0.000003 loss -1.6186\n",
      "layer norms 0.9451 0.9833 0.6539 0.9968\n",
      "logdet: 2.1209, prior p: 0.4984\n",
      "epoch 96 lr 0.000002 loss -1.6188\n",
      "layer norms 0.9452 0.9819 0.6502 0.9995\n",
      "logdet: 2.1187, prior p: 0.4997\n",
      "epoch 97 lr 0.000002 loss -1.6187\n",
      "layer norms 0.9495 0.9832 0.6538 1.0062\n",
      "logdet: 2.1161, prior p: 0.5031\n",
      "epoch 98 lr 0.000001 loss -1.6187\n",
      "layer norms 0.9389 0.9758 0.6482 1.0007\n",
      "logdet: 2.1191, prior p: 0.5004\n",
      "epoch 99 lr 0.000001 loss -1.6188\n",
      "layer norms 0.9469 0.9836 0.6521 0.9903\n",
      "logdet: 2.1179, prior p: 0.4951\n",
      "sampling complete\n"
     ]
    }
   ],
   "source": [
    "dataset = 'mnist'\n",
    "num_classes = 10\n",
    "img_size = 28\n",
    "channel_size = 1\n",
    "\n",
    "# we use a small model for fast demonstration, increase the model size for better results\n",
    "patch_size = 4\n",
    "channels = 128\n",
    "blocks = 4\n",
    "layers_per_block = 4\n",
    "# try different noise levels to see its effect\n",
    "noise_std = 0.1\n",
    "\n",
    "batch_size = 256\n",
    "lr = 5e-4\n",
    "# increase epochs for better results\n",
    "epochs = 100\n",
    "sample_freq = 5\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda' \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps' # if on mac\n",
    "else:\n",
    "    device = 'cpu' # if mps not available\n",
    "print(f'using device {device}')\n",
    "\n",
    "fixed_noise = torch.randn(num_classes * 10, (img_size // patch_size)**2, channel_size * patch_size ** 2, device=device)\n",
    "# fixed_noise = torch.randn(num_classes * 10, (img_size // patch_size)**2, channels, device=device)\n",
    "fixed_y = torch.arange(num_classes, device=device).view(-1, 1).repeat(1, 10).flatten()\n",
    "\n",
    "transform = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((img_size, img_size)),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "data = tv.datasets.MNIST('.', transform=transform, train=True, download=True)\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "model = Model(in_channels=channel_size, img_size=img_size, patch_size=patch_size, \n",
    "              channels=channels, num_blocks=blocks, layers_per_block=layers_per_block,\n",
    "              num_classes=num_classes).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), betas=(0.9, 0.95), lr=lr, weight_decay=1e-4)\n",
    "lr_schedule = utils.CosineLRSchedule(optimizer, len(data_loader), epochs * len(data_loader), 1e-6, lr)\n",
    "\n",
    "model_name = f'{patch_size}_{channels}_{blocks}_{layers_per_block}_{noise_std:.2f}_linears_with_residual'\n",
    "sample_dir = notebook_output_path / f'{dataset}_samples_{model_name}'\n",
    "ckpt_file = notebook_output_path / f'{dataset}_model_{model_name}.pth'\n",
    "sample_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = 0\n",
    "    for x, y in data_loader:\n",
    "        x = x.to(device)\n",
    "        eps = noise_std * torch.randn_like(x)\n",
    "        x = x + eps\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        z, outputs, logdets = model(x, y)\n",
    "        loss = model.get_loss(z, logdets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_schedule.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    print(f\"epoch {epoch} lr {optimizer.param_groups[0]['lr']:.6f} loss {losses / len(data_loader):.4f}\")\n",
    "    print('layer norms', ' '.join([f'{z.pow(2).mean():.4f}' for z in outputs]))\n",
    "    print(f'logdet: {logdets.mean():.4f}, prior p: {0.5 * z.pow(2).mean():.4f}')\n",
    "    if (epoch + 1) % sample_freq == 0:\n",
    "        with torch.no_grad():\n",
    "            samples = model.reverse(fixed_noise, fixed_y)\n",
    "        tv.utils.save_image(samples, sample_dir / f'samples_{epoch:03d}.png', normalize=True, nrow=10)\n",
    "        latents = model.unpatchify(z[:100])\n",
    "        tv.utils.save_image(latents, sample_dir / f'latent_{epoch:03d}.png', normalize=True, nrow=10)\n",
    "        print(f'sampling complete. Sample mean: {samples.mean():.4f}, std: {samples.std():.4f}')\n",
    "        print(f'latent mean: {latents.mean():.4f}, std: {latents.std():.4f}')\n",
    "    print('\\n')\n",
    "torch.save(model.state_dict(), ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd3fcf68-b9e5-4840-a26e-5091a16e98c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy %98.56\n"
     ]
    }
   ],
   "source": [
    "# now we can also evaluate the model by turning it into a classifier with Bayes rule, p(y|x) = p(y)p(x|y)/p(x)\n",
    "data = tv.datasets.MNIST('.', transform=transform, train=False, download=False)\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "num_correct = 0\n",
    "num_examples = 0\n",
    "for x, y in data_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    eps = noise_std * torch.randn_like(x)\n",
    "    x = x.repeat(num_classes, 1, 1, 1)\n",
    "    y_ = torch.arange(num_classes, device=device).view(-1, 1).repeat(1, y.size(0)).flatten()\n",
    "    with torch.no_grad():\n",
    "        z, outputs, logdets = model(x, y_)\n",
    "        losses = 0.5 * z.pow(2).mean(dim=[1, 2]) - logdets # keep the batch dimension\n",
    "        pred = losses.reshape(num_classes, y.size(0)).argmin(dim=0)\n",
    "    num_correct += (pred == y).sum()\n",
    "    num_examples += y.size(0)\n",
    "print(f'Accuracy %{100 * num_correct / num_examples:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c5005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "Unitary logdet: 0.00\n",
      "Unitary logdet: -0.00\n",
      "Unitary logdet: -0.00\n",
      "Unitary logdet: 0.00\n",
      "Number of parameters: 3.24M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2783271/2412898454.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"runs/notebook/mnist_model_4_128_4_4_0.10_linears_with_residual.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([-0.7094], device='cuda:0'), std: tensor([0.6018], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from transformer_flow import Model\n",
    "import utils\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\" # set GPU\n",
    "utils.set_random_seed(100)\n",
    "\n",
    "num_classes = 10\n",
    "img_size = 28\n",
    "channel_size = 1\n",
    "\n",
    "# we use a small model for fast demonstration, increase the model size for better results\n",
    "patch_size = 4\n",
    "channels = 128\n",
    "blocks = 4\n",
    "layers_per_block = 4\n",
    "# try different noise levels to see its effect\n",
    "noise_std = 0.1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda' \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps' # if on mac\n",
    "else:\n",
    "    device = 'cpu' # if mps not available\n",
    "print(f'using device {device}')\n",
    "\n",
    "fixed_noise = torch.randn(num_classes * 10, (img_size // patch_size)**2, channel_size * patch_size ** 2, device=device)\n",
    "# fixed_noise = torch.randn(num_classes * 10, (img_size // patch_size)**2, channels, device=device)\n",
    "fixed_y = torch.arange(num_classes, device=device).view(-1, 1).repeat(1, 10).flatten()\n",
    "\n",
    "# load the model\n",
    "model = Model(in_channels=channel_size, img_size=img_size, patch_size=patch_size, \n",
    "              channels=channels, num_blocks=blocks, layers_per_block=layers_per_block,\n",
    "              num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"runs/notebook/mnist_model_4_128_4_4_0.10_linears_with_residual.pth\"))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    samples = model.reverse(fixed_noise, fixed_y)\n",
    "    # print the mean and std of the samples\n",
    "    mean = samples.mean(dim=[0, 2, 3])\n",
    "    std = samples.std(dim=[0, 2, 3])\n",
    "    print(f'mean: {mean}, std: {std}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
