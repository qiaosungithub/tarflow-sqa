{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413d2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import os\n",
    "from transformer_flow import Model\n",
    "import utils\n",
    "import pathlib\n",
    "from utils import sqa_save\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\" # set GPU\n",
    "\n",
    "utils.set_random_seed(100)\n",
    "notebook_output_path = pathlib.Path('runs/notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "Number of parameters: 3.23M\n",
      "epoch 0 lr 0.002000 loss -1.2315\n",
      "layer norms 1.0803 0.9744 1.7220 0.9654 1.8649 0.9933 0.9970\n",
      "logdet: 1.9110, prior p: 0.4985\n",
      "\n",
      "\n",
      "epoch 1 lr 0.001999 loss -1.4687\n",
      "layer norms 0.7003 0.9187 1.1680 0.8880 1.1711 0.9636 0.9945\n",
      "logdet: 2.0153, prior p: 0.4972\n",
      "\n",
      "\n",
      "epoch 2 lr 0.001998 loss -1.5286\n",
      "layer norms 0.4520 0.8815 1.0381 0.8485 0.9112 0.9496 0.9825\n",
      "logdet: 2.0205, prior p: 0.4913\n",
      "\n",
      "\n",
      "epoch 3 lr 0.001995 loss -1.5484\n",
      "layer norms 0.3385 0.8569 0.9959 0.8286 0.8401 0.9461 1.0065\n",
      "logdet: 2.0567, prior p: 0.5033\n",
      "\n",
      "\n",
      "epoch 4 lr 0.001992 loss -1.5584\n",
      "layer norms 0.2651 0.8396 0.9473 0.8166 0.7817 0.9476 0.9919\n",
      "logdet: 2.0473, prior p: 0.4960\n",
      "\n",
      "\n",
      "epoch 5 lr 0.001987 loss -1.5654\n",
      "layer norms 0.2167 0.8273 0.8848 0.8100 0.7436 0.9513 0.9955\n",
      "logdet: 2.0551, prior p: 0.4977\n",
      "\n",
      "\n",
      "epoch 6 lr 0.001982 loss -1.5705\n",
      "layer norms 0.1755 0.8177 0.8742 0.8071 0.7039 0.9572 0.9942\n",
      "logdet: 2.0717, prior p: 0.4971\n",
      "\n",
      "\n",
      "epoch 7 lr 0.001975 loss -1.5744\n",
      "layer norms 0.1489 0.8109 0.8666 0.8062 0.6746 0.9635 0.9966\n",
      "logdet: 2.0745, prior p: 0.4983\n",
      "\n",
      "\n",
      "epoch 8 lr 0.001968 loss -1.5775\n",
      "layer norms 0.1279 0.8061 0.8679 0.8057 0.6433 0.9710 1.0154\n",
      "logdet: 2.0850, prior p: 0.5077\n",
      "\n",
      "\n",
      "epoch 9 lr 0.001960 loss -1.5800\n",
      "layer norms 0.1173 0.8031 0.8390 0.8065 0.6379 0.9778 1.0116\n",
      "logdet: 2.0844, prior p: 0.5058\n",
      "sampling complete. Sample mean: -0.7478, std: 0.6128, max: 1.8416, min: -1.7169\n",
      "latent mean: 0.0059, std: 1.0081\n",
      "\n",
      "\n",
      "epoch 10 lr 0.001950 loss -1.5822\n",
      "layer norms 0.0990 0.8012 0.8290 0.8082 0.6366 0.9860 1.0074\n",
      "logdet: 2.0868, prior p: 0.5037\n",
      "\n",
      "\n",
      "epoch 11 lr 0.001940 loss -1.5841\n",
      "layer norms 0.0904 0.8001 0.8291 0.8109 0.5979 0.9936 0.9849\n",
      "logdet: 2.0740, prior p: 0.4925\n",
      "\n",
      "\n",
      "epoch 12 lr 0.001928 loss -1.5857\n",
      "layer norms 0.0778 0.8000 0.8291 0.8140 0.6032 1.0017 0.9906\n",
      "logdet: 2.0778, prior p: 0.4953\n",
      "\n",
      "\n",
      "epoch 13 lr 0.001916 loss -1.5874\n",
      "layer norms 0.0695 0.8002 0.8212 0.8168 0.6023 1.0101 1.0004\n",
      "logdet: 2.0941, prior p: 0.5002\n",
      "\n",
      "\n",
      "epoch 14 lr 0.001903 loss -1.5885\n",
      "layer norms 0.0650 0.8014 0.8149 0.8208 0.5902 1.0186 1.0001\n",
      "logdet: 2.0915, prior p: 0.5001\n",
      "\n",
      "\n",
      "epoch 15 lr 0.001889 loss -1.5900\n",
      "layer norms 0.0579 0.8019 0.8002 0.8263 0.5732 1.0272 1.0178\n",
      "logdet: 2.0978, prior p: 0.5089\n",
      "\n",
      "\n",
      "epoch 16 lr 0.001874 loss -1.5911\n",
      "layer norms 0.0549 0.8027 0.7950 0.8301 0.5604 1.0351 1.0038\n",
      "logdet: 2.1023, prior p: 0.5019\n",
      "\n",
      "\n",
      "epoch 17 lr 0.001858 loss -1.5919\n",
      "layer norms 0.0503 0.8029 0.8026 0.8341 0.5677 1.0425 0.9982\n",
      "logdet: 2.0944, prior p: 0.4991\n",
      "\n",
      "\n",
      "epoch 18 lr 0.001841 loss -1.5931\n",
      "layer norms 0.0479 0.8032 0.7880 0.8379 0.5502 1.0519 0.9967\n",
      "logdet: 2.0940, prior p: 0.4984\n",
      "\n",
      "\n",
      "epoch 19 lr 0.001824 loss -1.5940\n",
      "layer norms 0.0440 0.8030 0.7714 0.8422 0.5436 1.0594 1.0037\n",
      "logdet: 2.0849, prior p: 0.5019\n",
      "sampling complete. Sample mean: -0.7410, std: 0.6137, max: 1.7098, min: -1.9903\n",
      "latent mean: 0.0089, std: 0.9985\n",
      "\n",
      "\n",
      "epoch 20 lr 0.001805 loss -1.5948\n",
      "layer norms 0.0423 0.8009 0.7646 0.8468 0.5336 1.0671 1.0031\n",
      "logdet: 2.0887, prior p: 0.5016\n",
      "\n",
      "\n",
      "epoch 21 lr 0.001786 loss -1.5958\n",
      "layer norms 0.0379 0.7991 0.7421 0.8505 0.5295 1.0747 0.9956\n",
      "logdet: 2.0990, prior p: 0.4978\n",
      "\n",
      "\n",
      "epoch 22 lr 0.001766 loss -1.5969\n",
      "layer norms 0.0380 0.7961 0.7290 0.8537 0.5137 1.0833 0.9944\n",
      "logdet: 2.0924, prior p: 0.4972\n",
      "\n",
      "\n",
      "epoch 23 lr 0.001745 loss -1.5974\n",
      "layer norms 0.0344 0.7940 0.7100 0.8578 0.5045 1.0907 0.9929\n",
      "logdet: 2.0964, prior p: 0.4964\n",
      "\n",
      "\n",
      "epoch 24 lr 0.001724 loss -1.5981\n",
      "layer norms 0.0331 0.7918 0.7101 0.8617 0.5079 1.0979 0.9964\n",
      "logdet: 2.0892, prior p: 0.4982\n",
      "\n",
      "\n",
      "epoch 25 lr 0.001702 loss -1.5988\n",
      "layer norms 0.0311 0.7892 0.6857 0.8657 0.4943 1.1057 0.9958\n",
      "logdet: 2.0971, prior p: 0.4979\n",
      "\n",
      "\n",
      "epoch 26 lr 0.001679 loss -1.5995\n",
      "layer norms 0.0312 0.7875 0.6724 0.8691 0.4877 1.1121 0.9920\n",
      "logdet: 2.0899, prior p: 0.4960\n",
      "\n",
      "\n",
      "epoch 27 lr 0.001655 loss -1.6004\n",
      "layer norms 0.0296 0.7844 0.6561 0.8730 0.4803 1.1188 1.0032\n",
      "logdet: 2.0998, prior p: 0.5016\n",
      "\n",
      "\n",
      "epoch 28 lr 0.001631 loss -1.6006\n",
      "layer norms 0.0291 0.7802 0.6400 0.8766 0.4761 1.1255 1.0118\n",
      "logdet: 2.1071, prior p: 0.5059\n",
      "\n",
      "\n",
      "epoch 29 lr 0.001606 loss -1.6012\n",
      "layer norms 0.0284 0.7765 0.6291 0.8802 0.4717 1.1318 0.9998\n",
      "logdet: 2.0994, prior p: 0.4999\n",
      "sampling complete. Sample mean: -0.7405, std: 0.6209, max: 1.7308, min: -1.6359\n",
      "latent mean: -0.0036, std: 0.9976\n",
      "\n",
      "\n",
      "epoch 30 lr 0.001580 loss -1.6017\n",
      "layer norms 0.0266 0.7739 0.6276 0.8838 0.4645 1.1385 0.9965\n",
      "logdet: 2.0913, prior p: 0.4983\n",
      "\n",
      "\n",
      "epoch 31 lr 0.001554 loss -1.6022\n",
      "layer norms 0.0266 0.7718 0.5959 0.8871 0.4637 1.1444 0.9919\n",
      "logdet: 2.1010, prior p: 0.4959\n",
      "\n",
      "\n",
      "epoch 32 lr 0.001527 loss -1.6028\n",
      "layer norms 0.0256 0.7667 0.5879 0.8900 0.4582 1.1516 0.9907\n",
      "logdet: 2.1032, prior p: 0.4954\n",
      "\n",
      "\n",
      "epoch 33 lr 0.001500 loss -1.6035\n",
      "layer norms 0.0247 0.7621 0.5811 0.8932 0.4510 1.1574 0.9899\n",
      "logdet: 2.0978, prior p: 0.4949\n",
      "\n",
      "\n",
      "epoch 34 lr 0.001473 loss -1.6039\n",
      "layer norms 0.0242 0.7584 0.5719 0.8969 0.4387 1.1628 0.9887\n",
      "logdet: 2.1003, prior p: 0.4943\n",
      "\n",
      "\n",
      "epoch 35 lr 0.001444 loss -1.6045\n",
      "layer norms 0.0236 0.7525 0.5634 0.8994 0.4343 1.1689 1.0156\n",
      "logdet: 2.1071, prior p: 0.5078\n",
      "\n",
      "\n",
      "epoch 36 lr 0.001416 loss -1.6049\n",
      "layer norms 0.0231 0.7493 0.5378 0.9026 0.4394 1.1742 0.9997\n",
      "logdet: 2.1049, prior p: 0.4999\n",
      "\n",
      "\n",
      "epoch 37 lr 0.001387 loss -1.6053\n",
      "layer norms 0.0230 0.7403 0.5245 0.9053 0.4310 1.1794 0.9946\n",
      "logdet: 2.0997, prior p: 0.4973\n",
      "\n",
      "\n",
      "epoch 38 lr 0.001357 loss -1.6058\n",
      "layer norms 0.0223 0.7299 0.5111 0.9077 0.4326 1.1840 0.9941\n",
      "logdet: 2.1015, prior p: 0.4971\n",
      "\n",
      "\n",
      "epoch 39 lr 0.001327 loss -1.6064\n",
      "layer norms 0.0221 0.7246 0.5042 0.9106 0.4204 1.1894 0.9959\n",
      "logdet: 2.0986, prior p: 0.4980\n",
      "sampling complete. Sample mean: -0.7375, std: 0.6218, max: 1.8839, min: -2.1925\n",
      "latent mean: 0.0054, std: 0.9951\n",
      "\n",
      "\n",
      "epoch 40 lr 0.001297 loss -1.6068\n",
      "layer norms 0.0223 0.7153 0.4795 0.9129 0.4243 1.1941 0.9978\n",
      "logdet: 2.1089, prior p: 0.4989\n",
      "\n",
      "\n",
      "epoch 41 lr 0.001267 loss -1.6075\n",
      "layer norms 0.0220 0.7051 0.4655 0.9141 0.4230 1.1983 1.0064\n",
      "logdet: 2.1085, prior p: 0.5032\n",
      "\n",
      "\n",
      "epoch 42 lr 0.001236 loss -1.6079\n",
      "layer norms 0.0217 0.7019 0.4452 0.9153 0.4061 1.2022 0.9971\n",
      "logdet: 2.1056, prior p: 0.4986\n",
      "\n",
      "\n",
      "epoch 43 lr 0.001205 loss -1.6082\n",
      "layer norms 0.0217 0.6875 0.4337 0.9167 0.4024 1.2068 1.0056\n",
      "logdet: 2.1125, prior p: 0.5028\n",
      "\n",
      "\n",
      "epoch 44 lr 0.001174 loss -1.6089\n",
      "layer norms 0.0216 0.6807 0.4055 0.9188 0.3982 1.2102 0.9970\n",
      "logdet: 2.1065, prior p: 0.4985\n",
      "\n",
      "\n",
      "epoch 45 lr 0.001143 loss -1.6091\n",
      "layer norms 0.0214 0.6649 0.3995 0.9210 0.4017 1.2142 1.0006\n",
      "logdet: 2.1107, prior p: 0.5003\n",
      "\n",
      "\n",
      "epoch 46 lr 0.001111 loss -1.6098\n",
      "layer norms 0.0213 0.6588 0.3831 0.9220 0.3961 1.2175 1.0085\n",
      "logdet: 2.1135, prior p: 0.5043\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = 'mnist'\n",
    "num_classes = 10\n",
    "img_size = 28\n",
    "channel_size = 1\n",
    "\n",
    "# we use a small model for fast demonstration, increase the model size for better results\n",
    "patch_size = 4\n",
    "channels = 128\n",
    "blocks = 4\n",
    "layers_per_block = 4\n",
    "# try different noise levels to see its effect\n",
    "noise_std = 0.1\n",
    "\n",
    "batch_size = 256\n",
    "lr = 2e-3\n",
    "# increase epochs for better results\n",
    "epochs = 100\n",
    "sample_freq = 10\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda' \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps' # if on mac\n",
    "else:\n",
    "    device = 'cpu' # if mps not available\n",
    "print(f'using device {device}')\n",
    "\n",
    "fixed_noise = torch.randn(num_classes * 10, (img_size // patch_size)**2, channel_size * patch_size ** 2, device=device)\n",
    "fixed_y = torch.arange(num_classes, device=device).view(-1, 1).repeat(1, 10).flatten()\n",
    "\n",
    "transform = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((img_size, img_size)),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "data = tv.datasets.MNIST('.', transform=transform, train=True, download=True)\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "model = Model(in_channels=channel_size, img_size=img_size, patch_size=patch_size, \n",
    "              channels=channels, num_blocks=blocks, layers_per_block=layers_per_block,\n",
    "              num_classes=num_classes).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), betas=(0.9, 0.95), lr=lr, weight_decay=1e-4)\n",
    "lr_schedule = utils.CosineLRSchedule(optimizer, len(data_loader), epochs * len(data_loader), 1e-6, lr)\n",
    "\n",
    "model_name = f'bn'\n",
    "sample_dir = notebook_output_path / f'{dataset}_samples_{model_name}'\n",
    "ckpt_file = notebook_output_path / f'{dataset}_model_{model_name}.pth'\n",
    "sample_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = 0\n",
    "    for x, y in data_loader:\n",
    "        x = x.to(device)\n",
    "        eps = noise_std * torch.randn_like(x)\n",
    "        x = x + eps\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        z, outputs, logdets = model(x, y)\n",
    "        loss = model.get_loss(z, logdets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_schedule.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    print(f\"epoch {epoch} lr {optimizer.param_groups[0]['lr']:.6f} loss {losses / len(data_loader):.4f}\")\n",
    "    print('layer norms', ' '.join([f'{z.pow(2).mean():.4f}' for z in outputs]))\n",
    "    print(f'logdet: {logdets.mean():.4f}, prior p: {0.5 * z.pow(2).mean():.4f}')\n",
    "    if (epoch + 1) % sample_freq == 0:\n",
    "        with torch.no_grad():\n",
    "            samples = model.reverse(fixed_noise, fixed_y)\n",
    "        sqa_save(samples, sample_dir / f'samples_{epoch:03d}.png')\n",
    "        latents = model.unpatchify(z[:100])\n",
    "        sqa_save(latents, sample_dir / f'latent_{epoch:03d}.png')\n",
    "        print(f'sampling complete. Sample mean: {samples.mean():.4f}, std: {samples.std():.4f}, max: {samples.max():.4f}, min: {samples.min():.4f}')\n",
    "        print(f'latent mean: {latents.mean():.4f}, std: {latents.std():.4f}')\n",
    "    print('\\n')\n",
    "torch.save(model.state_dict(), ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3fcf68-b9e5-4840-a26e-5091a16e98c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy %98.35\n"
     ]
    }
   ],
   "source": [
    "# now we can also evaluate the model by turning it into a classifier with Bayes rule, p(y|x) = p(y)p(x|y)/p(x)\n",
    "data = tv.datasets.MNIST('.', transform=transform, train=False, download=False)\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "num_correct = 0\n",
    "num_examples = 0\n",
    "for x, y in data_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    eps = noise_std * torch.randn_like(x)\n",
    "    x = x.repeat(num_classes, 1, 1, 1)\n",
    "    y_ = torch.arange(num_classes, device=device).view(-1, 1).repeat(1, y.size(0)).flatten()\n",
    "    with torch.no_grad():\n",
    "        z, outputs, logdets = model(x, y_)\n",
    "        losses = 0.5 * z.pow(2).mean(dim=[1, 2]) - logdets # keep the batch dimension\n",
    "        pred = losses.reshape(num_classes, y.size(0)).argmin(dim=0)\n",
    "    num_correct += (pred == y).sum()\n",
    "    num_examples += y.size(0)\n",
    "print(f'Accuracy %{100 * num_correct / num_examples:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import os\n",
    "# from transformer_flow import Model\n",
    "# import utils\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\" # set GPU\n",
    "# utils.set_random_seed(100)\n",
    "\n",
    "# num_classes = 10\n",
    "# img_size = 28\n",
    "# channel_size = 1\n",
    "\n",
    "# # we use a small model for fast demonstration, increase the model size for better results\n",
    "# patch_size = 4\n",
    "# channels = 128\n",
    "# blocks = 4\n",
    "# layers_per_block = 4\n",
    "# # try different noise levels to see its effect\n",
    "# noise_std = 0.1\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     device = 'cuda' \n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = 'mps' # if on mac\n",
    "# else:\n",
    "#     device = 'cpu' # if mps not available\n",
    "# print(f'using device {device}')\n",
    "\n",
    "# fixed_noise = torch.randn(num_classes * 10, (img_size // patch_size)**2, channel_size * patch_size ** 2, device=device)\n",
    "# # fixed_noise = torch.randn(num_classes * 10, (img_size // patch_size)**2, channels, device=device)\n",
    "# fixed_y = torch.arange(num_classes, device=device).view(-1, 1).repeat(1, 10).flatten()\n",
    "\n",
    "# # load the model\n",
    "# model = Model(in_channels=channel_size, img_size=img_size, patch_size=patch_size, \n",
    "#               channels=channels, num_blocks=blocks, layers_per_block=layers_per_block,\n",
    "#               num_classes=num_classes).to(device)\n",
    "# model.load_state_dict(torch.load(\"runs/notebook/mnist_model_4_128_4_4_0.10_linears_with_residual.pth\"))\n",
    "# model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     samples = model.reverse(fixed_noise, fixed_y)\n",
    "#     # print the mean and std of the samples\n",
    "#     mean = samples.mean(dim=[0, 2, 3])\n",
    "#     std = samples.std(dim=[0, 2, 3])\n",
    "#     print(f'mean: {mean}, std: {std}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
